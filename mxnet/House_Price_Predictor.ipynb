{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "House Price Predictor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNmU1wvwKndHx10x+kGkTpv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LoniQin/deep_learning_notebooks/blob/master/House_Price_Predictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27EMDLapBS20"
      },
      "source": [
        "## Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2q45MTVBPpc"
      },
      "source": [
        "from mxnet import autograd, gluon, init, nd\n",
        "from mxnet.gluon import data as gdata, loss as gloss, nn\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGdN1THFBp8-"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_kWfqxcBeeY"
      },
      "source": [
        "url = \"https://raw.githubusercontent.com/LoniQin/deep_learning_notebooks/master/\"\n",
        "train_data = pd.read_csv(url + 'data/kaggle_house_pred_train.csv')\n",
        "test_data = pd.read_csv(url + 'data/kaggle_house_pred_test.csv')\n",
        "all_features = pd.concat((train_data.iloc[:, 1:-1], test_data.iloc[:, 1:]))\n",
        "\n",
        "numeric_features = all_features.dtypes[all_features.dtypes != 'object'].index\n",
        "# Standardization\n",
        "all_features[numeric_features] = all_features[numeric_features].apply(lambda x : (x - x.mean()) / (x.std()))\n",
        "all_features[numeric_features] = all_features[numeric_features].fillna(0)\n",
        "# Change discrete numerical value to indicative value\n",
        "all_features = pd.get_dummies(all_features, dummy_na=True)\n",
        "n_train = train_data.shape[0]\n",
        "train_featrues = nd.array(all_features[:n_train].values)\n",
        "test_featrues = nd.array(all_features[n_train:].values)\n",
        "train_labels = nd.array(train_data.SalePrice.values).reshape((-1, 1))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkxAamS4EP9y"
      },
      "source": [
        "## Define constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HunFLJE6ER8G"
      },
      "source": [
        "loss = gloss.L2Loss()\n",
        "k, num_epochs, learning_rate, weight_decay, batch_size = 6, 100, 0.1, 0.1, 64"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cV69xDQeDnwA"
      },
      "source": [
        "## Define model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vChjzRg4D_6T"
      },
      "source": [
        "def get_net():\n",
        "    net = nn.Sequential()\n",
        "    net.add(nn.Dense(10))\n",
        "    net.add(nn.Dropout(0.01))\n",
        "    net.add(nn.Dense(1))\n",
        "    net.initialize()\n",
        "    return net"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20_PTPD7Ee-6"
      },
      "source": [
        "## Define loss function\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxSWk-0xEl1x"
      },
      "source": [
        "def log_rmse(net, features, labels):\n",
        "    clipped_preds = nd.clip(net(features), 1, float('inf'))\n",
        "    rmse = nd.sqrt(2 * loss(clipped_preds.log(), labels.log()).mean())\n",
        "    return rmse.asscalar()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McyuBAf6EtT5"
      },
      "source": [
        "## Define traning function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltVXZcrwEhzg"
      },
      "source": [
        "def train(net, train_features, train_labels, test_features, test_labels, num_epochs, learning_rate, weight_decay, batch_size):\n",
        "    train_ls, test_ls = [], []\n",
        "    train_iter = gdata.DataLoader(gdata.ArrayDataset(train_features, train_labels), batch_size, shuffle=True)\n",
        "    trainer = gluon.Trainer(net.collect_params(), 'adam', {'learning_rate': learning_rate, 'wd': weight_decay})\n",
        "    for epoch in range(num_epochs):\n",
        "        for X, y in train_iter:\n",
        "            with autograd.record():\n",
        "                l = loss(net(X), y)\n",
        "            l.backward()\n",
        "            trainer.step(batch_size)\n",
        "        train_ls.append(log_rmse(net, train_features, train_labels))\n",
        "        if test_labels is not None:\n",
        "            test_ls.append(log_rmse(net, test_features, test_labels))\n",
        "    return train_ls, test_ls"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etByzsmgEz9s"
      },
      "source": [
        "## Define K Fold algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MVM9PQwBMcK"
      },
      "source": [
        "\n",
        "def get_k_fold_data(k, i, X, y):\n",
        "    assert k > 1\n",
        "    fold_size = X.shape[0] // k\n",
        "    X_train, y_train = None, None\n",
        "    for j in range(k):\n",
        "        idx = slice(j * fold_size, (j + 1) * fold_size)\n",
        "        X_part = X[idx, :]\n",
        "        y_part = y[idx]\n",
        "        if j == i:\n",
        "            X_valid, y_valid = X_part, y_part\n",
        "        elif  X_train is None:\n",
        "            X_train, y_train = X_part, y_part\n",
        "        else:\n",
        "            X_train = nd.concat(X_train, X_part, dim = 0)\n",
        "            y_train = nd.concat(y_train, y_part, dim = 0)\n",
        "    return X_train, y_train, X_valid, y_valid\n",
        "\n",
        "def k_fold(k, X_train, y_train, num_epochs, learning_rate, weight_decay, batch_size):\n",
        "    train_l_sum , valid_l_sum = 0, 0\n",
        "    for i in range(k):\n",
        "        data = get_k_fold_data(k, i, X_train, y_train)\n",
        "        net = get_net()\n",
        "        train_ls, valid_ls = train(net, *data, num_epochs, learning_rate, weight_decay, batch_size)\n",
        "        train_l_sum += train_ls[-1]\n",
        "        valid_l_sum += valid_ls[-1]\n",
        "        #if i == 0:\n",
        "           # utils.semilogy(range(1, num_epochs  + 1), train_ls, 'epochs', 'rmse', range(1, num_epochs  + 1), valid_ls, ['train', 'valid'])\n",
        "        print(\"fold %d, train rmse %f, valid rmse %f\" % (i, train_ls[-1], valid_ls[-1]))\n",
        "    return train_l_sum / k, valid_l_sum / k\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFLQnFFME5M2"
      },
      "source": [
        "## Putting it all together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lff5z868E8MA",
        "outputId": "75565b94-4fc0-44b1-806c-10e0002e8012"
      },
      "source": [
        "train_l, valid_l = k_fold(k, train_featrues, train_labels, num_epochs, learning_rate, weight_decay, batch_size)\n",
        "print(\"%d-fold validation: avg train rmse %f, avg valid rmse %f\" % (k, train_l, valid_l))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold 0, train rmse 0.125407, valid rmse 0.153833\n",
            "fold 1, train rmse 0.127392, valid rmse 0.142196\n",
            "fold 2, train rmse 0.117930, valid rmse 0.163810\n",
            "fold 3, train rmse 0.127066, valid rmse 0.130273\n",
            "fold 4, train rmse 0.127552, valid rmse 0.150990\n",
            "fold 5, train rmse 0.122720, valid rmse 0.164433\n",
            "6-fold validation: avg train rmse 0.124678, avg valid rmse 0.150923\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}