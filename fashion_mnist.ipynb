{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from mxnet.gluon import data as gdata\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "import time \n",
    "from mxnet import autograd, nd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "learning_rate = 0.1\n",
    "num_epochs = 10\n",
    "num_inputs = 784\n",
    "num_outputs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = gdata.vision.FashionMNIST(train=True)\n",
    "mnist_test = gdata.vision.FashionMNIST(train=False)\n",
    "transformer = gdata.vision.transforms.ToTensor()\n",
    "train_iter = gdata.DataLoader(mnist_train.transform_first(transformer), batch_size, shuffle=True, num_workers=4)\n",
    "test_iter = gdata.DataLoader(mnist_test.transform_first(transformer), batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_fashion_mnist(images, labels):\n",
    "    display.set_matplotlib_formats('svg')\n",
    "    _, figs = plt.subplots(1, len(images), figsize = (12, 12))\n",
    "    for fig, image, label in zip(figs, images, labels):\n",
    "        fig.imshow(image.reshape((28, 28)).asnumpy())\n",
    "        fig.set_title(label)\n",
    "        fig.axes.get_xaxis().set_visible(False)\n",
    "        fig.axes.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 864x864 with 9 Axes>"
      ]
     },
     "execution_count": 0,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = mnist_train[0:9]\n",
    "show_fashion_mnist(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X):\n",
    "    x_exp = X.exp()\n",
    "    partition = x_exp.sum(axis = 1, keepdims = True)\n",
    "    return x_exp / partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net(X, w, b):\n",
    "    Y = nd.dot(X.reshape((-1, num_inputs)), w) + b\n",
    "    return softmax(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define cross entropy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(y_hat, y):\n",
    "    return  -nd.pick(y_hat, y).log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define SGD function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(params, lr, batch_size):\n",
    "    for i in range(len(params)):\n",
    "        nd.elemwise_sub(params[i], lr * params[i].grad / batch_size, out=params[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1 Elapsed time:1.50s accuracy:49.23%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:2 Elapsed time:1.44s accuracy:63.99%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:3 Elapsed time:1.87s accuracy:68.18%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:4 Elapsed time:1.78s accuracy:70.64%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:5 Elapsed time:2.19s accuracy:72.22%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:6 Elapsed time:2.15s accuracy:73.41%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:7 Elapsed time:2.23s accuracy:74.33%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:8 Elapsed time:2.12s accuracy:75.04%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:9 Elapsed time:2.35s accuracy:75.67%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10 Elapsed time:2.23s accuracy:76.19%\n"
     ]
    }
   ],
   "source": [
    "w = nd.random.normal(scale=1.0, shape=(num_inputs, num_outputs))\n",
    "b = nd.zeros(num_outputs)\n",
    "w.attach_grad()\n",
    "b.attach_grad()\n",
    "loss = cross_entropy\n",
    "start = time.time()\n",
    "# Train models\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    acc_sum, n = 0.0, 0\n",
    "    total = float(len(mnist_train))\n",
    "    for X, y in train_iter:\n",
    "        with autograd.record():\n",
    "            y_hat = net(X, w, b)\n",
    "            l = loss(y_hat, y).sum()\n",
    "        l.backward()\n",
    "        sgd([w, b], learning_rate, batch_size)\n",
    "        acc_sum += (y_hat.argmax(axis=1) == y.astype('float32')).sum().asscalar()\n",
    "    print(\"Epoch:%d Elapsed time:%.2fs accuracy:%.2f%%\" % (epoch, time.time() - start, (acc_sum / total) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict data and display images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fashion_mnist_labels(labels):\n",
    "    text_Labels =['t-shirt', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
    "    return [text_Labels[int(i)] for i in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in test_iter:\n",
    "    true_labels = get_fashion_mnist_labels(y.asnumpy())\n",
    "    pred_labels = get_fashion_mnist_labels(net(X, w, b).argmax(axis=1).asnumpy())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "titles = [true + \"\\n\" + pred for true, pred in zip(true_labels, pred_labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 864x864 with 9 Axes>"
      ]
     },
     "execution_count": 0,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_fashion_mnist(X[0:9], titles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}